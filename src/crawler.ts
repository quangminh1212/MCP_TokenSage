/**
 * Model Data Crawler
 * Crawl th√¥ng tin models t·ª´ OpenRouter API v√† c√°c ngu·ªìn kh√°c
 * Ch·∫°y: npx tsx src/crawler.ts ho·∫∑c npm run update-models
 */

import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ƒê∆∞·ªùng d·∫´n l∆∞u data
const DATA_DIR = path.join(__dirname, '..', 'data');
const MODELS_FILE = path.join(DATA_DIR, 'models.json');
const PRICING_FILE = path.join(DATA_DIR, 'pricing.json');
const ENCODINGS_FILE = path.join(DATA_DIR, 'encodings.json');

// Interfaces
interface OpenRouterModel {
    id: string;
    name: string;
    description?: string;
    context_length: number;
    pricing: {
        prompt: string;
        completion: string;
        request?: string;
        image?: string;
    };
    top_provider?: {
        context_length?: number;
        max_completion_tokens?: number;
        is_moderated?: boolean;
    };
    per_request_limits?: unknown;
    architecture?: {
        modality?: string;
        tokenizer?: string;
        instruct_type?: string;
    };
}

interface ModelInfo {
    id: string;
    name: string;
    provider: string;
    description: string;
    contextWindow: number;
    maxOutputTokens?: number;
    inputPricePer1M: number;
    outputPricePer1M: number;
    modality?: string;
    tokenizer?: string;
    isModerated?: boolean;
    lastUpdated: string;
}

interface CrawlResult {
    success: boolean;
    source: string;
    modelsCount: number;
    timestamp: string;
    models: ModelInfo[];
}

// Encoding mapping cho token counting
const TOKENIZER_TO_ENCODING: Record<string, string> = {
    tiktoken: 'cl100k_base',
    cl100k_base: 'cl100k_base',
    o200k_base: 'o200k_base',
    p50k_base: 'p50k_base',
    r50k_base: 'r50k_base',
    // C√°c model m·ªõi c·ªßa OpenAI th∆∞·ªùng d√πng o200k_base
    'gpt-4o': 'o200k_base',
    'gpt-4': 'cl100k_base',
    claude: 'cl100k_base',
    llama: 'cl100k_base',
    mistral: 'cl100k_base',
    gemini: 'cl100k_base',
};

/**
 * X√°c ƒë·ªãnh encoding d·ª±a tr√™n model ID
 */
function determineEncoding(modelId: string, tokenizer?: string): string {
    // N·∫øu c√≥ tokenizer info
    if (tokenizer && TOKENIZER_TO_ENCODING[tokenizer]) {
        return TOKENIZER_TO_ENCODING[tokenizer];
    }

    // X√°c ƒë·ªãnh theo model ID
    const id = modelId.toLowerCase();

    // OpenAI o200k_base models
    if (id.includes('gpt-4o') || id.includes('o1') || id.includes('o3')) {
        return 'o200k_base';
    }

    // OpenAI cl100k_base models
    if (id.includes('gpt-4') || id.includes('gpt-3.5')) {
        return 'cl100k_base';
    }

    // Legacy OpenAI
    if (
        id.includes('davinci') ||
        id.includes('curie') ||
        id.includes('babbage') ||
        id.includes('ada')
    ) {
        if (id.includes('text-davinci-003') || id.includes('text-davinci-002')) {
            return 'p50k_base';
        }
        return 'r50k_base';
    }

    // M·∫∑c ƒë·ªãnh d√πng cl100k_base cho c√°c model kh√°c
    return 'cl100k_base';
}

/**
 * Tr√≠ch xu·∫•t provider t·ª´ model ID
 */
function extractProvider(modelId: string): string {
    const parts = modelId.split('/');
    if (parts.length > 1) {
        return parts[0];
    }

    // X√°c ƒë·ªãnh provider t·ª´ t√™n model
    const id = modelId.toLowerCase();
    if (id.includes('gpt') || id.includes('o1') || id.includes('o3')) return 'openai';
    if (id.includes('claude')) return 'anthropic';
    if (id.includes('gemini')) return 'google';
    if (id.includes('llama')) return 'meta-llama';
    if (id.includes('mistral') || id.includes('mixtral')) return 'mistralai';
    if (id.includes('deepseek')) return 'deepseek';
    if (id.includes('qwen')) return 'qwen';
    if (id.includes('command') || id.includes('embed')) return 'cohere';
    if (id.includes('grok')) return 'x-ai';
    if (id.includes('titan') || id.includes('nova')) return 'amazon';
    if (id.includes('jamba') || id.includes('j2')) return 'ai21';
    if (id.includes('yi')) return '01-ai';
    if (id.includes('glm')) return 'zhipu';

    return 'unknown';
}

/**
 * Crawl models t·ª´ OpenRouter API
 */
async function crawlOpenRouter(): Promise<CrawlResult> {
    console.log('üì° Crawling from OpenRouter API...');

    try {
        const response = await fetch('https://openrouter.ai/api/v1/models');
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }

        const data = (await response.json()) as { data: OpenRouterModel[] };
        const models: ModelInfo[] = [];

        for (const model of data.data) {
            // Parse pricing (gi√° per token -> per 1M tokens)
            const inputPrice = parseFloat(model.pricing.prompt) * 1_000_000;
            const outputPrice = parseFloat(model.pricing.completion) * 1_000_000;

            const modelInfo: ModelInfo = {
                id: model.id,
                name: model.name || model.id.split('/').pop() || model.id,
                provider: extractProvider(model.id),
                description: model.description || '',
                contextWindow: model.context_length || model.top_provider?.context_length || 4096,
                maxOutputTokens: model.top_provider?.max_completion_tokens,
                inputPricePer1M: Math.round(inputPrice * 1000000) / 1000000,
                outputPricePer1M: Math.round(outputPrice * 1000000) / 1000000,
                modality: model.architecture?.modality,
                tokenizer: model.architecture?.tokenizer,
                isModerated: model.top_provider?.is_moderated,
                lastUpdated: new Date().toISOString(),
            };

            models.push(modelInfo);
        }

        console.log(`‚úÖ Found ${models.length} models from OpenRouter`);

        return {
            success: true,
            source: 'openrouter',
            modelsCount: models.length,
            timestamp: new Date().toISOString(),
            models,
        };
    } catch (error) {
        console.error('‚ùå Failed to crawl OpenRouter:', error);
        return {
            success: false,
            source: 'openrouter',
            modelsCount: 0,
            timestamp: new Date().toISOString(),
            models: [],
        };
    }
}

/**
 * T·∫°o file encoding mapping t·ª´ models data
 */
function generateEncodingMap(models: ModelInfo[]): Record<string, string> {
    const encodings: Record<string, string> = {};

    for (const model of models) {
        // D√πng ID ng·∫Øn (kh√¥ng c√≥ provider prefix)
        const shortId = model.id.includes('/') ? model.id.split('/').pop()! : model.id;
        encodings[shortId] = determineEncoding(model.id, model.tokenizer);

        // C≈©ng l∆∞u full ID
        encodings[model.id] = determineEncoding(model.id, model.tokenizer);
    }

    return encodings;
}

/**
 * T·∫°o file pricing t·ª´ models data
 */
function generatePricingMap(models: ModelInfo[]): Record<
    string,
    {
        name: string;
        inputPricePer1M: number;
        outputPricePer1M: number;
        contextWindow: number;
        description: string;
    }
> {
    const pricing: Record<
        string,
        {
            name: string;
            inputPricePer1M: number;
            outputPricePer1M: number;
            contextWindow: number;
            description: string;
        }
    > = {};

    for (const model of models) {
        // D√πng ID ng·∫Øn cho key
        const shortId = model.id.includes('/') ? model.id.split('/').pop()! : model.id;

        pricing[shortId] = {
            name: model.name,
            inputPricePer1M: model.inputPricePer1M,
            outputPricePer1M: model.outputPricePer1M,
            contextWindow: model.contextWindow,
            description: model.description || `${model.provider} model`,
        };
    }

    return pricing;
}

/**
 * L∆∞u d·ªØ li·ªáu v√†o files
 */
function saveData(result: CrawlResult): void {
    // T·∫°o th∆∞ m·ª•c data n·∫øu ch∆∞a c√≥
    if (!fs.existsSync(DATA_DIR)) {
        fs.mkdirSync(DATA_DIR, { recursive: true });
        console.log('üìÅ Created data directory');
    }

    // L∆∞u full models data
    const modelsData = {
        lastUpdated: result.timestamp,
        source: result.source,
        count: result.modelsCount,
        models: result.models,
    };
    fs.writeFileSync(MODELS_FILE, JSON.stringify(modelsData, null, 2));
    console.log(`üíæ Saved ${result.modelsCount} models to ${MODELS_FILE}`);

    // L∆∞u pricing map
    const pricingMap = generatePricingMap(result.models);
    const pricingData = {
        lastUpdated: result.timestamp,
        source: result.source,
        count: Object.keys(pricingMap).length,
        pricing: pricingMap,
    };
    fs.writeFileSync(PRICING_FILE, JSON.stringify(pricingData, null, 2));
    console.log(`üíæ Saved pricing data to ${PRICING_FILE}`);

    // L∆∞u encoding map
    const encodingMap = generateEncodingMap(result.models);
    const encodingData = {
        lastUpdated: result.timestamp,
        count: Object.keys(encodingMap).length,
        encodings: encodingMap,
    };
    fs.writeFileSync(ENCODINGS_FILE, JSON.stringify(encodingData, null, 2));
    console.log(`üíæ Saved encoding data to ${ENCODINGS_FILE}`);
}

/**
 * Main function
 */
async function main(): Promise<void> {
    console.log('üöÄ MCP TokenSage - Model Data Crawler');
    console.log('=====================================\n');

    const startTime = Date.now();

    // Crawl t·ª´ OpenRouter
    const result = await crawlOpenRouter();

    if (result.success && result.models.length > 0) {
        // L∆∞u d·ªØ li·ªáu
        saveData(result);

        const elapsed = ((Date.now() - startTime) / 1000).toFixed(2);
        console.log(`\n‚ú® Crawl completed in ${elapsed}s`);
        console.log(`üìä Total models: ${result.modelsCount}`);

        // Th·ªëng k√™ theo provider
        const providers = new Map<string, number>();
        for (const model of result.models) {
            providers.set(model.provider, (providers.get(model.provider) || 0) + 1);
        }

        console.log('\nüìà Models by provider:');
        const sortedProviders = [...providers.entries()].sort((a, b) => b[1] - a[1]);
        for (const [provider, count] of sortedProviders.slice(0, 15)) {
            console.log(`   ${provider}: ${count}`);
        }
    } else {
        console.error('\n‚ùå Crawl failed! Using existing data if available.');
        process.exit(1);
    }
}

// Run
main().catch(console.error);
